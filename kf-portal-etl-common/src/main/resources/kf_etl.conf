io.kf.etl {

  spark {
    app.name = ""
    master = ""
  }

  postgresql {
    host = ""
    database = ""
    user = ""
    password = ""
  }

  elasticsearch {
    url = ""
    index = ""
  }

  hdfs {
    defaultFS = "hdfs://"
    root = ""
  }

  processors = [
    {
      name = "stage"
    },
    {
      name = "document"
      data_path = "/document" //this field is optional. Each job context should define the default values
    },
    {
      name = "index"
    }
  ]

  pipeline {

  }
}